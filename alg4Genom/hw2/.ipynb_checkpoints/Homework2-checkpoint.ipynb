{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import boyer_more helper\n",
    "from bm_preproc import BoyerMoore\n",
    "from kmer_index import Index\n",
    "import bisect\n",
    "class SubseqIndex(object):\n",
    "    \"\"\" Holds a subsequence index for a text T \"\"\"\n",
    "    \n",
    "    def __init__(self, t, k, ival):\n",
    "        \"\"\" Create index from all subsequences consisting of k characters\n",
    "            spaced ival positions apart.  E.g., SubseqIndex(\"ATAT\", 2, 2)\n",
    "            extracts (\"AA\", 0) and (\"TT\", 1). \"\"\"\n",
    "        self.k = k  # num characters per subsequence extracted\n",
    "        self.ival = ival  # space between them; 1=adjacent, 2=every other, etc\n",
    "        self.index = []\n",
    "        self.span = 1 + ival * (k - 1)\n",
    "        for i in range(len(t) - self.span + 1):  # for each subseq\n",
    "            self.index.append((t[i:i+self.span:ival], i))  # add (subseq, offset)\n",
    "        self.index.sort()  # alphabetize by subseq\n",
    "    \n",
    "    def query(self, p):\n",
    "        \"\"\" Return index hits for first subseq of p \"\"\"\n",
    "        subseq = p[:self.span:self.ival]  # query with first subseq\n",
    "        i = bisect.bisect_left(self.index, (subseq, -1))  # binary search\n",
    "        hits = []\n",
    "        while i < len(self.index):  # collect matching index entries\n",
    "            mismatches = 0\n",
    "            if self.index[i][0] != subseq:\n",
    "                    # mismatches += 1\n",
    "                    # if mismatches > 2:\n",
    "                        break\n",
    "            hits.append(self.index[i][1])\n",
    "            i += 1\n",
    "        return hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# naive \n",
    "def naive(p, t):\n",
    "    occurrences = []\n",
    "    for i in range(len(t) - len(p) + 1):  # loop over alignments\n",
    "        match = True\n",
    "        for j in range(len(p)):  # loop over characters\n",
    "            if t[i+j] != p[j]:  # compare characters\n",
    "                match = False\n",
    "                break\n",
    "        if match:\n",
    "            occurrences.append(i)  # all chars matched; record\n",
    "    return occurrences\n",
    "\n",
    "# naive with count \n",
    "# naive \n",
    "def naive_with_counts(p, t):\n",
    "    occurrences = []\n",
    "    alignComps = 0\n",
    "    chrComps = 0 \n",
    "    for i in range(len(t) - len(p) + 1):  # loop over alignments\n",
    "        alignComps += 1 \n",
    "        match = True\n",
    "        for j in range(len(p)):  # loop over characters\n",
    "            chrComps += 1 \n",
    "            if t[i+j] != p[j]:  # compare characters\n",
    "                match = False\n",
    "                break\n",
    "        if match:\n",
    "            occurrences.append(i)  # all chars matched; record\n",
    "    return occurrences, alignComps, chrComps\n",
    "\n",
    "# boyer_moore\n",
    "def boyer_moore(p, p_bm, t):\n",
    "    \"\"\" Do Boyer-Moore matching. p=pattern, t=text,\n",
    "        p_bm=BoyerMoore object for p \"\"\"\n",
    "    i = 0\n",
    "    occurrences = []\n",
    "    while i < len(t) - len(p) + 1:\n",
    "        shift = 1\n",
    "        mismatched = False\n",
    "        for j in range(len(p)-1, -1, -1):\n",
    "            if p[j] != t[i+j]:\n",
    "                skip_bc = p_bm.bad_character_rule(j, t[i+j])\n",
    "                skip_gs = p_bm.good_suffix_rule(j)\n",
    "                shift = max(shift, skip_bc, skip_gs)\n",
    "                mismatched = True\n",
    "                break\n",
    "        if not mismatched:\n",
    "            occurrences.append(i)\n",
    "            skip_gs = p_bm.match_skip()\n",
    "            shift = max(shift, skip_gs)\n",
    "        i += shift\n",
    "    return occurrences\n",
    "\n",
    "\n",
    "# boyer_moore with counts \n",
    "def boyer_moore_with_counts(p, p_bm, t):\n",
    "    \"\"\" Do Boyer-Moore matching. p=pattern, t=text,\n",
    "        p_bm=BoyerMoore object for p \"\"\"\n",
    "    i = 0\n",
    "    occurrences = []\n",
    "    alignComps = 0\n",
    "    chrComps = 0 \n",
    "    while i < len(t) - len(p) + 1:\n",
    "        alignComps += 1 \n",
    "        shift = 1\n",
    "        mismatched = False\n",
    "        for j in range(len(p)-1, -1, -1):\n",
    "            chrComps += 1\n",
    "            if p[j] != t[i+j]:\n",
    "                skip_bc = p_bm.bad_character_rule(j, t[i+j])\n",
    "                skip_gs = p_bm.good_suffix_rule(j)\n",
    "                shift = max(shift, skip_bc, skip_gs)\n",
    "                mismatched = True\n",
    "                break\n",
    "        if not mismatched:\n",
    "            occurrences.append(i)\n",
    "            skip_gs = p_bm.match_skip()\n",
    "            shift = max(shift, skip_gs)\n",
    "        i += shift\n",
    "    return occurrences, alignComps, chrComps\n",
    "\n",
    "# read genome \n",
    "# - filename: the file location of the genome file to read\n",
    "def readGenome(filename):\n",
    "    genome = ''\n",
    "    with open(filename, 'r') as f:\n",
    "        for line in f:\n",
    "            # ignore header line with genome information\n",
    "            if not line[0] == '>':\n",
    "                genome += line.rstrip()\n",
    "    return genome\n",
    "def naive_2mm(p, t):\n",
    "    occurrences = []\n",
    "    for i in range(len(t) - len(p) + 1):  # loop over alignments\n",
    "        match = True\n",
    "        miss = 0 \n",
    "        for j in range(len(p)): \n",
    "            if t[i+j] != p[j]:  # compare characters\n",
    "                miss = miss + 1\n",
    "                if miss > 2: \n",
    "                    match = False \n",
    "                    break \n",
    "        if match:\n",
    "            occurrences.append(i)  # all chars matched; record\n",
    "    return occurrences\n",
    "\n",
    "\n",
    "def approximate_match_boyer(p, t, n):\n",
    "    segment_length = int(round(len(p) / (n+1)))\n",
    "    all_matches = set()\n",
    "    hits = 0\n",
    "    for i in range(n+1):\n",
    "        start = i*segment_length\n",
    "        end = min((i+1)*segment_length, len(p))\n",
    "        p_bm = BoyerMoore(p[start:end], alphabet='ACGT')\n",
    "        matches = boyer_moore(p[start:end], p_bm, t)\n",
    "        hits += len(matches)\n",
    "        # Extend matching segments to see if whole p matches\n",
    "        for m in matches:\n",
    "            if m < start or m-start+len(p) > len(t):\n",
    "                continue\n",
    "            mismatches = 0\n",
    "            for j in range(0, start):\n",
    "                if not p[j] == t[m-start+j]:\n",
    "                    mismatches += 1\n",
    "                    if mismatches > n:\n",
    "                        break\n",
    "            for j in range(end, len(p)):\n",
    "                if not p[j] == t[m-start+j]:\n",
    "                    mismatches += 1\n",
    "                    if mismatches > n:\n",
    "                        break\n",
    "            if mismatches <= n:\n",
    "                all_matches.add(m - start)\n",
    "    return list(all_matches), hits \n",
    "\n",
    "\n",
    "def approximate_match_index(p, index, t, n):\n",
    "    segment_length = int(round(len(p) / (n+1)))\n",
    "    all_matches = set()\n",
    "    hits = 0 \n",
    "    for i in range(n+1):\n",
    "        start = i*segment_length\n",
    "        end = min((i+1)*segment_length, len(p))\n",
    "        matches = index.query(p[start:end])\n",
    "        hits += len(matches)\n",
    "        # Extend matching segments to see if whole p matches\n",
    "        for m in matches:\n",
    "            if m < start or m-start+len(p) > len(t):\n",
    "                continue\n",
    "            mismatches = 0\n",
    "            for j in range(0, start):\n",
    "                if not p[j] == t[m-start+j]:\n",
    "                    mismatches += 1\n",
    "                    if mismatches > n:\n",
    "                        break\n",
    "            for j in range(end, len(p)):\n",
    "                if not p[j] == t[m-start+j]:\n",
    "                    mismatches += 1\n",
    "                    if mismatches > n:\n",
    "                        break\n",
    "            if mismatches <= n:\n",
    "                all_matches.add(m - start)\n",
    "    return list(all_matches), hits \n",
    "\n",
    "        index.k = k  # num characters per subsequence extracted\n",
    "        self.ival = ival  # space between them; 1=adjacent, 2=every other, etc\n",
    "def approximate_match_index_sub(p, index, t, n):\n",
    "    segment_length = int(round(len(p) / (n+1)))\n",
    "    all_matches = set()\n",
    "    hits = 0 \n",
    "    for i in range(n+1):\n",
    "        start = i*segment_length\n",
    "        end = min((i+1)*segment_length, len(p))\n",
    "        matches = index.query(p[start:end])\n",
    "        hits += len(matches)\n",
    "        # Extend matching segments to see if whole p matches\n",
    "        for m in matches:\n",
    "            if m < start or m-start+len(p) > len(t):\n",
    "                continue\n",
    "            mismatches = 0\n",
    "            for j in range(0, start):\n",
    "                if not p[j] == t[m-start+j]:\n",
    "                    mismatches += 1\n",
    "                    if mismatches > n:\n",
    "                        break\n",
    "            for j in range(end, len(p)):\n",
    "                if not p[j] == t[m-start+j]:\n",
    "                    mismatches += 1\n",
    "                    if mismatches > n:\n",
    "                        break\n",
    "            if mismatches <= n:\n",
    "                all_matches.add(m - start)\n",
    "    return list(all_matches), hits \n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0  791k    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100  791k  100  791k    0     0  2138k      0 --:--:-- --:--:-- --:--:-- 2132k\n"
     ]
    }
   ],
   "source": [
    "!curl http://d28rh4a8wq0iu5.cloudfront.net/ads1/data/chr1.GRCh38.excerpt.fasta -o C:/Users/buehl/Documents/genomics/alg4Genom/hw2/lambd_virus.fa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40] 41 46\n"
     ]
    }
   ],
   "source": [
    "# test case 1 naive_with_counts\n",
    "p = 'word'\n",
    "t = 'there would have been a time for such a word'\n",
    "occurrences, num_alignments, num_character_comparisons = naive_with_counts(p, t)\n",
    "print(occurrences, num_alignments, num_character_comparisons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 19] 20 35\n"
     ]
    }
   ],
   "source": [
    "# test case 2 naive_with_counts\n",
    "p = 'needle'\n",
    "t = 'needle need noodle needle'\n",
    "occurrences, num_alignments, num_character_comparisons = naive_with_counts(p, t)\n",
    "print(occurrences, num_alignments, num_character_comparisons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40] 12 15\n"
     ]
    }
   ],
   "source": [
    "# test case 2 naive_with_counts\n",
    "p = 'word'\n",
    "t = 'there would have been a time for such a word'\n",
    "lowercase_alphabet = 'abcdefghijklmnopqrstuvwxyz '\n",
    "p_bm = BoyerMoore(p, lowercase_alphabet)\n",
    "occurrences, num_alignments, num_character_comparisons = boyer_moore_with_counts(p, p_bm, t)\n",
    "print(occurrences, num_alignments, num_character_comparisons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 19] 5 18\n"
     ]
    }
   ],
   "source": [
    "# test case 2 naive_with_counts\n",
    "p = 'needle'\n",
    "t = 'needle need noodle needle'\n",
    "p_bm = BoyerMoore(p, lowercase_alphabet)\n",
    "occurrences, num_alignments, num_character_comparisons = boyer_moore_with_counts(p, p_bm, t)\n",
    "print(occurrences, num_alignments, num_character_comparisons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[56922] 799954 984143\n"
     ]
    }
   ],
   "source": [
    "# Question 1 \n",
    "# define text \n",
    "t = readGenome(\"lambd_virus.fa\")\n",
    "p = \"GGCGCGGTGGCTCACGCCTGTAATCCCAGCACTTTGGGAGGCCGAGG\"\n",
    "lowercase_alphabet = 'ACGT'\n",
    "# run \n",
    "occurrences, num_alignments, num_character_comparisons = naive_with_counts(p, t)\n",
    "print(occurrences, num_alignments, num_character_comparisons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[56922] 127974 165191\n"
     ]
    }
   ],
   "source": [
    "# Question 2-3\n",
    "# define text \n",
    "t = readGenome(\"lambd_virus.fa\")\n",
    "p = \"GGCGCGGTGGCTCACGCCTGTAATCCCAGCACTTTGGGAGGCCGAGG\"\n",
    "lowercase_alphabet = 'ACGT'\n",
    "# pre-process\n",
    "p_bm = BoyerMoore(p, lowercase_alphabet)\n",
    "# run \n",
    "occurrences, num_alignments, num_character_comparisons = boyer_moore_with_counts(p, p_bm, t)\n",
    "print(occurrences, num_alignments, num_character_comparisons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[273669, 681737, 717706, 262042, 635931, 84641, 160162, 724927, 657496, 160729, 56922, 191452, 551134, 747359, 421221, 147558, 364263, 465647, 429299]\n",
      "90\n",
      "[273669, 681737, 717706, 262042, 635931, 84641, 160162, 724927, 657496, 160729, 56922, 191452, 551134, 747359, 421221, 147558, 364263, 465647, 429299]\n",
      "90\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "# Question 4\n",
    "t = readGenome(\"lambd_virus.fa\")\n",
    "p = \"GGCGCGGTGGCTCACGCCTGTAAT\"\n",
    "index = Index(t, 8)\n",
    "matches, hits = approximate_match_index(p, index, t, 2)\n",
    "print(matches)\n",
    "print(hits)\n",
    "matches, hits = approximate_match_boyer(p, t, 2)\n",
    "print(matches)\n",
    "print(hits)\n",
    "matches = naive_2mm(p, t)\n",
    "print(len(matches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('AAA', 0), ('TTT', 1)]\n",
      "[1]\n",
      "[1]\n",
      "TATAT\n"
     ]
    }
   ],
   "source": [
    "# Question 5 understanding \n",
    "ind = SubseqIndex('ATATAT', 3, 2)\n",
    "print(ind.index)\n",
    "p = 'TTATAT'\n",
    "print(ind.query(p[0:]))\n",
    "print(ind.query(p[1:]))\n",
    "print(p[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 14]\n",
      "46\n"
     ]
    }
   ],
   "source": [
    "# Question 5 tests\n",
    "t = 'to-morrow and to-morrow and to-morrow creeps in this petty pace'\n",
    "p = 'to-morrow and to-morrow '\n",
    "subseq_ind = SubseqIndex(t, 8, 3)\n",
    "occurrences, num_index_hits = approximate_match_index(p, subseq_ind,t,2)\n",
    "print(occurrences)\n",
    "print(num_index_hits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[712449, 651523, 273669, 83720, 681737, 717706, 551827, 262042, 635931, 471966, 84641, 160162, 207654, 84775, 199469, 18733, 322735, 621362, 18870, 472634, 719418, 724927, 523085, 108110, 707151, 251090, 657496, 160729, 56922, 191452, 551134, 747359, 421221, 147558, 364263, 465647, 429299, 141046, 746620, 22397]\n",
      "1085494\n"
     ]
    }
   ],
   "source": [
    "# Question 5 \n",
    "t = readGenome(\"lambd_virus.fa\")\n",
    "p = \"GGCGCGGTGGCTCACGCCTGTAAT\"\n",
    "index = SubseqIndex(t, 8, 3)\n",
    "matches, hits = approximate_match_index_sub(p, index, t, 2)\n",
    "print(matches)\n",
    "print(hits)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
